{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "#!pip install tensorflow==2.0.0-alpha0 \n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-dev20190602'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data(\"mnist.npz\")\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "    raw_perturb = tf.gradients(loss, images)[0]\n",
    "    normalized_per=tf.nn.l2_normalize(raw_perturb, axis=[1, 2, 3])\n",
    "    perturb =0.01 * tf.stop_gradient(normalized_per)\n",
    "    perturb_image_inputs = images + perturb\n",
    "    perturb_predictions = model(perturb_image_inputs)\n",
    "    perturb_loss = loss_object(labels, perturb_predictions)\n",
    "    all_loss = loss + perturb_loss\n",
    "  gradients = tape.gradient(all_loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(all_loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  predictions = model(images)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.280753493309021, Accuracy: 95.8183364868164, Test Loss: 0.05578523874282837, Test Accuracy: 98.22000122070312\n",
      "Epoch 2, Loss: 0.18032361567020416, Accuracy: 97.32083129882812, Test Loss: 0.05583876371383667, Test Accuracy: 98.17500305175781\n",
      "Epoch 3, Loss: 0.13333258032798767, Accuracy: 98.00999450683594, Test Loss: 0.05759581923484802, Test Accuracy: 98.1199951171875\n",
      "Epoch 4, Loss: 0.10752709954977036, Accuracy: 98.38958740234375, Test Loss: 0.06005034223198891, Test Accuracy: 98.0625\n",
      "Epoch 5, Loss: 0.089377760887146, Accuracy: 98.65766906738281, Test Loss: 0.06132921203970909, Test Accuracy: 98.13600158691406\n",
      "Epoch 6, Loss: 0.07705852389335632, Accuracy: 98.84249877929688, Test Loss: 0.06034369021654129, Test Accuracy: 98.22999572753906\n",
      "Epoch 7, Loss: 0.06748607009649277, Accuracy: 98.98428344726562, Test Loss: 0.06186548247933388, Test Accuracy: 98.27285766601562\n",
      "Epoch 8, Loss: 0.060236431658267975, Accuracy: 99.09166717529297, Test Loss: 0.062457744032144547, Test Accuracy: 98.31500244140625\n",
      "Epoch 9, Loss: 0.05442797392606735, Accuracy: 99.17926025390625, Test Loss: 0.06453564018011093, Test Accuracy: 98.33110809326172\n",
      "Epoch 10, Loss: 0.0498378649353981, Accuracy: 99.24832916259766, Test Loss: 0.06775526702404022, Test Accuracy: 98.3169937133789\n",
      "Epoch 11, Loss: 0.04578198865056038, Accuracy: 99.3095474243164, Test Loss: 0.06902990490198135, Test Accuracy: 98.32454681396484\n",
      "Epoch 12, Loss: 0.042618270963430405, Accuracy: 99.3580551147461, Test Loss: 0.07022873312234879, Test Accuracy: 98.336669921875\n",
      "Epoch 13, Loss: 0.03980755805969238, Accuracy: 99.40026092529297, Test Loss: 0.07131920009851456, Test Accuracy: 98.35615539550781\n",
      "Epoch 14, Loss: 0.03744436427950859, Accuracy: 99.43524169921875, Test Loss: 0.07259566336870193, Test Accuracy: 98.36785888671875\n",
      "Epoch 15, Loss: 0.035222455859184265, Accuracy: 99.46766662597656, Test Loss: 0.07462585717439651, Test Accuracy: 98.36800384521484\n",
      "Epoch 16, Loss: 0.0333067961037159, Accuracy: 99.4965591430664, Test Loss: 0.07638280093669891, Test Accuracy: 98.38062286376953\n",
      "Epoch 17, Loss: 0.03157992288470268, Accuracy: 99.52294158935547, Test Loss: 0.07840308547019958, Test Accuracy: 98.38352966308594\n",
      "Epoch 18, Loss: 0.030135445296764374, Accuracy: 99.54546356201172, Test Loss: 0.07933380454778671, Test Accuracy: 98.39611053466797\n",
      "Epoch 19, Loss: 0.02869291603565216, Accuracy: 99.56666564941406, Test Loss: 0.08137854188680649, Test Accuracy: 98.39263153076172\n",
      "Epoch 20, Loss: 0.02742726169526577, Accuracy: 99.58583068847656, Test Loss: 0.0825849324464798, Test Accuracy: 98.39800262451172\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
